{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras import layers, losses, optimizers\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210, 8)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_data=open('seeds_dataset.txt').read()\n",
    "text_data=text_data.split('\\n')\n",
    "\n",
    "df=pd.DataFrame(list(map(lambda x:x.split('\\t'), text_data)))\n",
    "df.drop(columns=[8,9],inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.26</td>\n",
       "      <td>14.84</td>\n",
       "      <td>0.871</td>\n",
       "      <td>5.763</td>\n",
       "      <td>3.312</td>\n",
       "      <td>2.221</td>\n",
       "      <td>5.22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.88</td>\n",
       "      <td>14.57</td>\n",
       "      <td>0.8811</td>\n",
       "      <td>5.554</td>\n",
       "      <td>3.333</td>\n",
       "      <td>1.018</td>\n",
       "      <td>4.956</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.29</td>\n",
       "      <td>14.09</td>\n",
       "      <td>0.905</td>\n",
       "      <td>5.291</td>\n",
       "      <td>3.337</td>\n",
       "      <td>2.699</td>\n",
       "      <td>4.825</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.84</td>\n",
       "      <td>13.94</td>\n",
       "      <td>0.8955</td>\n",
       "      <td>5.324</td>\n",
       "      <td>3.379</td>\n",
       "      <td>2.259</td>\n",
       "      <td>4.805</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.14</td>\n",
       "      <td>14.99</td>\n",
       "      <td>0.9034</td>\n",
       "      <td>5.658</td>\n",
       "      <td>3.562</td>\n",
       "      <td>1.355</td>\n",
       "      <td>5.175</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1       2      3      4      5      6  7\n",
       "0  15.26  14.84   0.871  5.763  3.312  2.221   5.22  1\n",
       "1  14.88  14.57  0.8811  5.554  3.333  1.018  4.956  1\n",
       "2  14.29  14.09   0.905  5.291  3.337  2.699  4.825  1\n",
       "3  13.84  13.94  0.8955  5.324  3.379  2.259  4.805  1\n",
       "4  16.14  14.99  0.9034  5.658  3.562  1.355  5.175  1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    70\n",
       "3    70\n",
       "1    70\n",
       "Name: 7, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[7].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "target=pd.get_dummies(df[7])\n",
    "\n",
    "df.drop(columns=7,inplace=True)\n",
    "\n",
    "scaler=StandardScaler()\n",
    "df=pd.DataFrame(scaler.fit_transform(df),columns=df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((151, 7), (38, 7), (21, 7), (151, 3), (38, 3), (21, 3))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, X_test, y, y_test = train_test_split(df,target,test_size=0.1)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X,y,test_size=0.2)\n",
    "\n",
    "X_train.shape, X_val.shape, X_test.shape, y_train.shape, y_val.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim = 32\n",
    "output_dim = 3\n",
    "\n",
    "class MLP(Model):\n",
    "    def __init__(self, hidden_dim, output_dim):\n",
    "        \n",
    "        #initializing methods of parent class (Model) that we are inheriting from \n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "        self.fc1 = tf.keras.Sequential([layers.Dense(hidden_dim, activation='sigmoid')])\n",
    "        self.fc2 = tf.keras.Sequential([layers.Dense(output_dim, activation='softmax')])\n",
    "    \n",
    "    def call(self,x):\n",
    "        hidden = self.fc1(x)\n",
    "        output = self.fc2(x)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "model = MLP(hidden_dim, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrop = ReduceLROnPlateau(factor=0.8, patience=3)\n",
    "estop = EarlyStopping(patience=10)\n",
    "\n",
    "optimizer = optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=losses.CategoricalCrossentropy(), metrics = 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense/kernel:0', 'dense/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['dense/kernel:0', 'dense/bias:0'] when minimizing the loss.\n",
      "5/5 [==============================] - 2s 261ms/step - loss: 1.3159 - accuracy: 0.2446 - val_loss: 1.0911 - val_accuracy: 0.3158\n",
      "Epoch 2/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 1.1520 - accuracy: 0.2505 - val_loss: 0.8643 - val_accuracy: 0.5789\n",
      "Epoch 3/200\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.8978 - accuracy: 0.5143 - val_loss: 0.6996 - val_accuracy: 0.8158\n",
      "Epoch 4/200\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.7676 - accuracy: 0.6643 - val_loss: 0.5864 - val_accuracy: 0.8684\n",
      "Epoch 5/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.6974 - accuracy: 0.6928 - val_loss: 0.5099 - val_accuracy: 0.8684\n",
      "Epoch 6/200\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.5744 - accuracy: 0.7913 - val_loss: 0.4571 - val_accuracy: 0.8684\n",
      "Epoch 7/200\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.5246 - accuracy: 0.7988 - val_loss: 0.4194 - val_accuracy: 0.9211\n",
      "Epoch 8/200\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.4944 - accuracy: 0.8453 - val_loss: 0.3915 - val_accuracy: 0.9211\n",
      "Epoch 9/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.4968 - accuracy: 0.8189 - val_loss: 0.3705 - val_accuracy: 0.9211\n",
      "Epoch 10/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.4201 - accuracy: 0.8454 - val_loss: 0.3536 - val_accuracy: 0.9211\n",
      "Epoch 11/200\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.3906 - accuracy: 0.8454 - val_loss: 0.3398 - val_accuracy: 0.9211\n",
      "Epoch 12/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.4363 - accuracy: 0.8290 - val_loss: 0.3282 - val_accuracy: 0.9211\n",
      "Epoch 13/200\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.4062 - accuracy: 0.8408 - val_loss: 0.3180 - val_accuracy: 0.9211\n",
      "Epoch 14/200\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.3690 - accuracy: 0.8742 - val_loss: 0.3096 - val_accuracy: 0.9211\n",
      "Epoch 15/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.3509 - accuracy: 0.8798 - val_loss: 0.3010 - val_accuracy: 0.9211\n",
      "Epoch 16/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.3659 - accuracy: 0.8499 - val_loss: 0.2945 - val_accuracy: 0.9211\n",
      "Epoch 17/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.3174 - accuracy: 0.8638 - val_loss: 0.2890 - val_accuracy: 0.9211\n",
      "Epoch 18/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.3232 - accuracy: 0.8447 - val_loss: 0.2822 - val_accuracy: 0.9211\n",
      "Epoch 19/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.3551 - accuracy: 0.8490 - val_loss: 0.2781 - val_accuracy: 0.9211\n",
      "Epoch 20/200\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.3393 - accuracy: 0.8617 - val_loss: 0.2718 - val_accuracy: 0.9211\n",
      "Epoch 21/200\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.3086 - accuracy: 0.8730 - val_loss: 0.2679 - val_accuracy: 0.9211\n",
      "Epoch 22/200\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.3229 - accuracy: 0.8604 - val_loss: 0.2635 - val_accuracy: 0.9211\n",
      "Epoch 23/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.3218 - accuracy: 0.8582 - val_loss: 0.2603 - val_accuracy: 0.9211\n",
      "Epoch 24/200\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.2968 - accuracy: 0.8834 - val_loss: 0.2563 - val_accuracy: 0.9211\n",
      "Epoch 25/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.2826 - accuracy: 0.8834 - val_loss: 0.2525 - val_accuracy: 0.9211\n",
      "Epoch 26/200\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.3404 - accuracy: 0.8552 - val_loss: 0.2500 - val_accuracy: 0.9211\n",
      "Epoch 27/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.2941 - accuracy: 0.8778 - val_loss: 0.2471 - val_accuracy: 0.8947\n",
      "Epoch 28/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.2730 - accuracy: 0.8969 - val_loss: 0.2442 - val_accuracy: 0.8947\n",
      "Epoch 29/200\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.2929 - accuracy: 0.8635 - val_loss: 0.2413 - val_accuracy: 0.8947\n",
      "Epoch 30/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.2597 - accuracy: 0.8804 - val_loss: 0.2382 - val_accuracy: 0.8947\n",
      "Epoch 31/200\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.2832 - accuracy: 0.8822 - val_loss: 0.2357 - val_accuracy: 0.8947\n",
      "Epoch 32/200\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.2494 - accuracy: 0.9030 - val_loss: 0.2328 - val_accuracy: 0.8947\n",
      "Epoch 33/200\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.2540 - accuracy: 0.9004 - val_loss: 0.2309 - val_accuracy: 0.8947\n",
      "Epoch 34/200\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.2380 - accuracy: 0.9082 - val_loss: 0.2283 - val_accuracy: 0.8947\n",
      "Epoch 35/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.2602 - accuracy: 0.8817 - val_loss: 0.2254 - val_accuracy: 0.8947\n",
      "Epoch 36/200\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.2494 - accuracy: 0.8765 - val_loss: 0.2245 - val_accuracy: 0.8947\n",
      "Epoch 37/200\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.2525 - accuracy: 0.8791 - val_loss: 0.2242 - val_accuracy: 0.8947\n",
      "Epoch 38/200\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.2511 - accuracy: 0.8813 - val_loss: 0.2216 - val_accuracy: 0.8947\n",
      "Epoch 39/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.2745 - accuracy: 0.8778 - val_loss: 0.2204 - val_accuracy: 0.8947\n",
      "Epoch 40/200\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.2419 - accuracy: 0.8817 - val_loss: 0.2184 - val_accuracy: 0.8947\n",
      "Epoch 41/200\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.2226 - accuracy: 0.9048 - val_loss: 0.2170 - val_accuracy: 0.8947\n",
      "Epoch 42/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.2695 - accuracy: 0.8818 - val_loss: 0.2139 - val_accuracy: 0.8947\n",
      "Epoch 43/200\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.2339 - accuracy: 0.9070 - val_loss: 0.2120 - val_accuracy: 0.8947\n",
      "Epoch 44/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.2664 - accuracy: 0.8944 - val_loss: 0.2105 - val_accuracy: 0.8947\n",
      "Epoch 45/200\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.2297 - accuracy: 0.9266 - val_loss: 0.2102 - val_accuracy: 0.8947\n",
      "Epoch 46/200\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.2007 - accuracy: 0.9253 - val_loss: 0.2085 - val_accuracy: 0.8947\n",
      "Epoch 47/200\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.2103 - accuracy: 0.9218 - val_loss: 0.2062 - val_accuracy: 0.8947\n",
      "Epoch 48/200\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.2145 - accuracy: 0.9079 - val_loss: 0.2052 - val_accuracy: 0.8947\n",
      "Epoch 49/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.2482 - accuracy: 0.8966 - val_loss: 0.2035 - val_accuracy: 0.8947\n",
      "Epoch 50/200\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.2313 - accuracy: 0.9066 - val_loss: 0.2020 - val_accuracy: 0.8947\n",
      "Epoch 51/200\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.2449 - accuracy: 0.9096 - val_loss: 0.2004 - val_accuracy: 0.8947\n",
      "Epoch 52/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.2279 - accuracy: 0.9031 - val_loss: 0.1989 - val_accuracy: 0.8947\n",
      "Epoch 53/200\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.2327 - accuracy: 0.9027 - val_loss: 0.1990 - val_accuracy: 0.8947\n",
      "Epoch 54/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.2357 - accuracy: 0.9066 - val_loss: 0.1968 - val_accuracy: 0.8947\n",
      "Epoch 55/200\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1848 - accuracy: 0.9227 - val_loss: 0.1955 - val_accuracy: 0.8947\n",
      "Epoch 56/200\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.2206 - accuracy: 0.8983 - val_loss: 0.1937 - val_accuracy: 0.8947\n",
      "Epoch 57/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 14ms/step - loss: 0.2246 - accuracy: 0.9049 - val_loss: 0.1938 - val_accuracy: 0.8947\n",
      "Epoch 58/200\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.2286 - accuracy: 0.9010 - val_loss: 0.1920 - val_accuracy: 0.8947\n",
      "Epoch 59/200\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.2233 - accuracy: 0.8888 - val_loss: 0.1906 - val_accuracy: 0.8947\n",
      "Epoch 60/200\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1731 - accuracy: 0.9309 - val_loss: 0.1899 - val_accuracy: 0.8947\n",
      "Epoch 61/200\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.2141 - accuracy: 0.9122 - val_loss: 0.1887 - val_accuracy: 0.8947\n",
      "Epoch 62/200\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1823 - accuracy: 0.9218 - val_loss: 0.1884 - val_accuracy: 0.8947\n",
      "Epoch 63/200\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.2265 - accuracy: 0.8983 - val_loss: 0.1889 - val_accuracy: 0.8947\n",
      "Epoch 64/200\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.2227 - accuracy: 0.9036 - val_loss: 0.1882 - val_accuracy: 0.8947\n",
      "Epoch 65/200\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1954 - accuracy: 0.9144 - val_loss: 0.1861 - val_accuracy: 0.8947\n",
      "Epoch 66/200\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.2161 - accuracy: 0.8918 - val_loss: 0.1853 - val_accuracy: 0.8947\n",
      "Epoch 67/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1902 - accuracy: 0.9153 - val_loss: 0.1841 - val_accuracy: 0.8947\n",
      "Epoch 68/200\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1739 - accuracy: 0.9275 - val_loss: 0.1835 - val_accuracy: 0.8947\n",
      "Epoch 69/200\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.2093 - accuracy: 0.9153 - val_loss: 0.1805 - val_accuracy: 0.8947\n",
      "Epoch 70/200\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.2080 - accuracy: 0.9079 - val_loss: 0.1786 - val_accuracy: 0.8947\n",
      "Epoch 71/200\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1890 - accuracy: 0.9240 - val_loss: 0.1774 - val_accuracy: 0.8947\n",
      "Epoch 72/200\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.2395 - accuracy: 0.8910 - val_loss: 0.1770 - val_accuracy: 0.8947\n",
      "Epoch 73/200\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.1672 - accuracy: 0.9353 - val_loss: 0.1769 - val_accuracy: 0.8947\n",
      "Epoch 74/200\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.2028 - accuracy: 0.9092 - val_loss: 0.1768 - val_accuracy: 0.8947\n",
      "Epoch 75/200\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.2277 - accuracy: 0.8971 - val_loss: 0.1743 - val_accuracy: 0.8947\n",
      "Epoch 76/200\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.2036 - accuracy: 0.9092 - val_loss: 0.1734 - val_accuracy: 0.8947\n",
      "Epoch 77/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1830 - accuracy: 0.9153 - val_loss: 0.1710 - val_accuracy: 0.8947\n",
      "Epoch 78/200\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1903 - accuracy: 0.9214 - val_loss: 0.1699 - val_accuracy: 0.8947\n",
      "Epoch 79/200\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1860 - accuracy: 0.9097 - val_loss: 0.1702 - val_accuracy: 0.8947\n",
      "Epoch 80/200\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.2085 - accuracy: 0.9031 - val_loss: 0.1704 - val_accuracy: 0.8947\n",
      "Epoch 81/200\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.2128 - accuracy: 0.8988 - val_loss: 0.1701 - val_accuracy: 0.9211\n",
      "Epoch 82/200\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.2125 - accuracy: 0.8845 - val_loss: 0.1707 - val_accuracy: 0.9211\n",
      "Epoch 83/200\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.2068 - accuracy: 0.8988 - val_loss: 0.1701 - val_accuracy: 0.9211\n",
      "Epoch 84/200\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.1869 - accuracy: 0.9114 - val_loss: 0.1689 - val_accuracy: 0.9211\n",
      "Epoch 85/200\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1990 - accuracy: 0.8975 - val_loss: 0.1679 - val_accuracy: 0.9211\n",
      "Epoch 86/200\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.2121 - accuracy: 0.8944 - val_loss: 0.1681 - val_accuracy: 0.9211\n",
      "Epoch 87/200\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1835 - accuracy: 0.9205 - val_loss: 0.1676 - val_accuracy: 0.9211\n",
      "Epoch 88/200\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.1774 - accuracy: 0.9161 - val_loss: 0.1681 - val_accuracy: 0.9211\n",
      "Epoch 89/200\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.2077 - accuracy: 0.8849 - val_loss: 0.1674 - val_accuracy: 0.9211\n",
      "Epoch 90/200\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.2005 - accuracy: 0.8953 - val_loss: 0.1656 - val_accuracy: 0.9211\n",
      "Epoch 91/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1920 - accuracy: 0.9010 - val_loss: 0.1645 - val_accuracy: 0.9211\n",
      "Epoch 92/200\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1884 - accuracy: 0.9109 - val_loss: 0.1634 - val_accuracy: 0.9211\n",
      "Epoch 93/200\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.1555 - accuracy: 0.9200 - val_loss: 0.1633 - val_accuracy: 0.9211\n",
      "Epoch 94/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1705 - accuracy: 0.9114 - val_loss: 0.1621 - val_accuracy: 0.9211\n",
      "Epoch 95/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1728 - accuracy: 0.9075 - val_loss: 0.1611 - val_accuracy: 0.9211\n",
      "Epoch 96/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1819 - accuracy: 0.9109 - val_loss: 0.1607 - val_accuracy: 0.9211\n",
      "Epoch 97/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.2094 - accuracy: 0.8979 - val_loss: 0.1594 - val_accuracy: 0.9211\n",
      "Epoch 98/200\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.1993 - accuracy: 0.8949 - val_loss: 0.1594 - val_accuracy: 0.9211\n",
      "Epoch 99/200\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.1820 - accuracy: 0.9079 - val_loss: 0.1587 - val_accuracy: 0.9211\n",
      "Epoch 100/200\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1519 - accuracy: 0.9365 - val_loss: 0.1588 - val_accuracy: 0.9211\n",
      "Epoch 101/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1813 - accuracy: 0.9049 - val_loss: 0.1591 - val_accuracy: 0.9211\n",
      "Epoch 102/200\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.1796 - accuracy: 0.8936 - val_loss: 0.1586 - val_accuracy: 0.9211\n",
      "Epoch 103/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1612 - accuracy: 0.9122 - val_loss: 0.1583 - val_accuracy: 0.9211\n",
      "Epoch 104/200\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1991 - accuracy: 0.8931 - val_loss: 0.1583 - val_accuracy: 0.9211\n",
      "Epoch 105/200\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.2041 - accuracy: 0.8884 - val_loss: 0.1590 - val_accuracy: 0.9211\n",
      "Epoch 106/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1587 - accuracy: 0.9135 - val_loss: 0.1585 - val_accuracy: 0.9211\n",
      "Epoch 107/200\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.1884 - accuracy: 0.8957 - val_loss: 0.1584 - val_accuracy: 0.9211\n",
      "Epoch 108/200\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1853 - accuracy: 0.9014 - val_loss: 0.1572 - val_accuracy: 0.9211\n",
      "Epoch 109/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.1749 - accuracy: 0.9131 - val_loss: 0.1568 - val_accuracy: 0.9211\n",
      "Epoch 110/200\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.2203 - accuracy: 0.8784 - val_loss: 0.1559 - val_accuracy: 0.9211\n",
      "Epoch 111/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1717 - accuracy: 0.9049 - val_loss: 0.1554 - val_accuracy: 0.9211\n",
      "Epoch 112/200\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.1847 - accuracy: 0.9001 - val_loss: 0.1552 - val_accuracy: 0.9211\n",
      "Epoch 113/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1822 - accuracy: 0.9101 - val_loss: 0.1544 - val_accuracy: 0.9211\n",
      "Epoch 114/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1501 - accuracy: 0.9300 - val_loss: 0.1542 - val_accuracy: 0.9211\n",
      "Epoch 115/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 17ms/step - loss: 0.1724 - accuracy: 0.9166 - val_loss: 0.1538 - val_accuracy: 0.9211\n",
      "Epoch 116/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1692 - accuracy: 0.9196 - val_loss: 0.1539 - val_accuracy: 0.9211\n",
      "Epoch 117/200\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.1486 - accuracy: 0.9244 - val_loss: 0.1539 - val_accuracy: 0.9211\n",
      "Epoch 118/200\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.1629 - accuracy: 0.9105 - val_loss: 0.1541 - val_accuracy: 0.9211\n",
      "Epoch 119/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1514 - accuracy: 0.9326 - val_loss: 0.1539 - val_accuracy: 0.9211\n",
      "Epoch 120/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1741 - accuracy: 0.9075 - val_loss: 0.1539 - val_accuracy: 0.9211\n",
      "Epoch 121/200\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.1462 - accuracy: 0.9287 - val_loss: 0.1532 - val_accuracy: 0.9211\n",
      "Epoch 122/200\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.1997 - accuracy: 0.8897 - val_loss: 0.1527 - val_accuracy: 0.9211\n",
      "Epoch 123/200\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.1784 - accuracy: 0.9131 - val_loss: 0.1523 - val_accuracy: 0.9211\n",
      "Epoch 124/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1916 - accuracy: 0.8849 - val_loss: 0.1515 - val_accuracy: 0.9211\n",
      "Epoch 125/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1417 - accuracy: 0.9253 - val_loss: 0.1512 - val_accuracy: 0.9211\n",
      "Epoch 126/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1984 - accuracy: 0.8849 - val_loss: 0.1510 - val_accuracy: 0.9211\n",
      "Epoch 127/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1507 - accuracy: 0.9161 - val_loss: 0.1502 - val_accuracy: 0.9211\n",
      "Epoch 128/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1687 - accuracy: 0.9079 - val_loss: 0.1495 - val_accuracy: 0.9211\n",
      "Epoch 129/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1571 - accuracy: 0.9092 - val_loss: 0.1499 - val_accuracy: 0.9211\n",
      "Epoch 130/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1792 - accuracy: 0.8979 - val_loss: 0.1502 - val_accuracy: 0.9211\n",
      "Epoch 131/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1629 - accuracy: 0.9192 - val_loss: 0.1495 - val_accuracy: 0.9211\n",
      "Epoch 132/200\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1906 - accuracy: 0.8914 - val_loss: 0.1496 - val_accuracy: 0.9211\n",
      "Epoch 133/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1882 - accuracy: 0.9014 - val_loss: 0.1498 - val_accuracy: 0.9211\n",
      "Epoch 134/200\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1547 - accuracy: 0.9248 - val_loss: 0.1496 - val_accuracy: 0.9211\n",
      "Epoch 135/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1492 - accuracy: 0.9192 - val_loss: 0.1493 - val_accuracy: 0.9211\n",
      "Epoch 136/200\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.1930 - accuracy: 0.8914 - val_loss: 0.1491 - val_accuracy: 0.9211\n",
      "Epoch 137/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1308 - accuracy: 0.9309 - val_loss: 0.1493 - val_accuracy: 0.9211\n",
      "Epoch 138/200\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.1807 - accuracy: 0.9057 - val_loss: 0.1488 - val_accuracy: 0.9211\n",
      "Epoch 139/200\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1635 - accuracy: 0.9161 - val_loss: 0.1488 - val_accuracy: 0.9211\n",
      "Epoch 140/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.2216 - accuracy: 0.8688 - val_loss: 0.1488 - val_accuracy: 0.9211\n",
      "Epoch 141/200\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.1644 - accuracy: 0.9148 - val_loss: 0.1486 - val_accuracy: 0.9211\n",
      "Epoch 142/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1880 - accuracy: 0.8853 - val_loss: 0.1485 - val_accuracy: 0.9211\n",
      "Epoch 143/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1907 - accuracy: 0.8970 - val_loss: 0.1485 - val_accuracy: 0.9211\n",
      "Epoch 144/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1411 - accuracy: 0.9222 - val_loss: 0.1483 - val_accuracy: 0.9211\n",
      "Epoch 145/200\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.1383 - accuracy: 0.9309 - val_loss: 0.1480 - val_accuracy: 0.9211\n",
      "Epoch 146/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1656 - accuracy: 0.9001 - val_loss: 0.1479 - val_accuracy: 0.9211\n",
      "Epoch 147/200\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1521 - accuracy: 0.9131 - val_loss: 0.1474 - val_accuracy: 0.9211\n",
      "Epoch 148/200\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1793 - accuracy: 0.8975 - val_loss: 0.1473 - val_accuracy: 0.9211\n",
      "Epoch 149/200\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.1847 - accuracy: 0.8931 - val_loss: 0.1473 - val_accuracy: 0.9211\n",
      "Epoch 150/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1657 - accuracy: 0.9053 - val_loss: 0.1468 - val_accuracy: 0.9211\n",
      "Epoch 151/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1834 - accuracy: 0.8884 - val_loss: 0.1469 - val_accuracy: 0.9211\n",
      "Epoch 152/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1707 - accuracy: 0.9036 - val_loss: 0.1470 - val_accuracy: 0.9211\n",
      "Epoch 153/200\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.1432 - accuracy: 0.9227 - val_loss: 0.1471 - val_accuracy: 0.9211\n",
      "Epoch 154/200\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.1597 - accuracy: 0.9205 - val_loss: 0.1469 - val_accuracy: 0.9211\n",
      "Epoch 155/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1834 - accuracy: 0.8827 - val_loss: 0.1469 - val_accuracy: 0.9211\n",
      "Epoch 156/200\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.2068 - accuracy: 0.8836 - val_loss: 0.1468 - val_accuracy: 0.9211\n",
      "Epoch 157/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.1524 - accuracy: 0.9274 - val_loss: 0.1465 - val_accuracy: 0.9211\n",
      "Epoch 158/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1591 - accuracy: 0.9135 - val_loss: 0.1465 - val_accuracy: 0.9211\n",
      "Epoch 159/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1500 - accuracy: 0.9122 - val_loss: 0.1465 - val_accuracy: 0.9211\n",
      "Epoch 160/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1685 - accuracy: 0.9031 - val_loss: 0.1465 - val_accuracy: 0.9211\n",
      "Epoch 161/200\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1826 - accuracy: 0.8875 - val_loss: 0.1464 - val_accuracy: 0.9211\n",
      "Epoch 162/200\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.1661 - accuracy: 0.8970 - val_loss: 0.1464 - val_accuracy: 0.9211\n",
      "Epoch 163/200\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1560 - accuracy: 0.9096 - val_loss: 0.1463 - val_accuracy: 0.9211\n",
      "Epoch 164/200\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1619 - accuracy: 0.9235 - val_loss: 0.1462 - val_accuracy: 0.9211\n",
      "Epoch 165/200\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.1755 - accuracy: 0.9066 - val_loss: 0.1462 - val_accuracy: 0.9211\n",
      "Epoch 166/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1547 - accuracy: 0.9109 - val_loss: 0.1462 - val_accuracy: 0.9211\n",
      "Epoch 167/200\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.1356 - accuracy: 0.9305 - val_loss: 0.1459 - val_accuracy: 0.9211\n",
      "Epoch 168/200\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.1824 - accuracy: 0.8944 - val_loss: 0.1462 - val_accuracy: 0.9211\n",
      "Epoch 169/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1634 - accuracy: 0.9092 - val_loss: 0.1461 - val_accuracy: 0.9211\n",
      "Epoch 170/200\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.1473 - accuracy: 0.9201 - val_loss: 0.1462 - val_accuracy: 0.9211\n",
      "Epoch 171/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1843 - accuracy: 0.8997 - val_loss: 0.1460 - val_accuracy: 0.9211\n",
      "Epoch 172/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1780 - accuracy: 0.9036 - val_loss: 0.1460 - val_accuracy: 0.9211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 173/200\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.1313 - accuracy: 0.9344 - val_loss: 0.1459 - val_accuracy: 0.9211\n",
      "Epoch 174/200\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.1755 - accuracy: 0.9114 - val_loss: 0.1458 - val_accuracy: 0.9211\n",
      "Epoch 175/200\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1816 - accuracy: 0.9149 - val_loss: 0.1459 - val_accuracy: 0.9211\n",
      "Epoch 176/200\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.1345 - accuracy: 0.9335 - val_loss: 0.1458 - val_accuracy: 0.9211\n",
      "Epoch 177/200\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1883 - accuracy: 0.9023 - val_loss: 0.1456 - val_accuracy: 0.9211\n",
      "Epoch 178/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1889 - accuracy: 0.8940 - val_loss: 0.1455 - val_accuracy: 0.9211\n",
      "Epoch 179/200\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.1378 - accuracy: 0.9266 - val_loss: 0.1453 - val_accuracy: 0.9211\n",
      "Epoch 180/200\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.1790 - accuracy: 0.8997 - val_loss: 0.1452 - val_accuracy: 0.9211\n",
      "Epoch 181/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1670 - accuracy: 0.9136 - val_loss: 0.1452 - val_accuracy: 0.9211\n",
      "Epoch 182/200\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.1625 - accuracy: 0.9088 - val_loss: 0.1451 - val_accuracy: 0.9211\n",
      "Epoch 183/200\n",
      "5/5 [==============================] - 0s 20ms/step - loss: 0.1600 - accuracy: 0.9240 - val_loss: 0.1449 - val_accuracy: 0.9211\n",
      "Epoch 184/200\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.1795 - accuracy: 0.9075 - val_loss: 0.1449 - val_accuracy: 0.9211\n",
      "Epoch 185/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1819 - accuracy: 0.8997 - val_loss: 0.1448 - val_accuracy: 0.9211\n",
      "Epoch 186/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1762 - accuracy: 0.9040 - val_loss: 0.1447 - val_accuracy: 0.9211\n",
      "Epoch 187/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1692 - accuracy: 0.9157 - val_loss: 0.1447 - val_accuracy: 0.9211\n",
      "Epoch 188/200\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1440 - accuracy: 0.9266 - val_loss: 0.1448 - val_accuracy: 0.9211\n",
      "Epoch 189/200\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.1475 - accuracy: 0.9361 - val_loss: 0.1448 - val_accuracy: 0.9211\n",
      "Epoch 190/200\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.2015 - accuracy: 0.8954 - val_loss: 0.1448 - val_accuracy: 0.9211\n",
      "Epoch 191/200\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.1879 - accuracy: 0.9154 - val_loss: 0.1447 - val_accuracy: 0.9211\n",
      "Epoch 192/200\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1459 - accuracy: 0.9375 - val_loss: 0.1447 - val_accuracy: 0.9211\n",
      "Epoch 193/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1465 - accuracy: 0.9362 - val_loss: 0.1447 - val_accuracy: 0.9211\n",
      "Epoch 194/200\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.1689 - accuracy: 0.9084 - val_loss: 0.1447 - val_accuracy: 0.9211\n",
      "Epoch 195/200\n",
      "5/5 [==============================] - 0s 19ms/step - loss: 0.1460 - accuracy: 0.9318 - val_loss: 0.1447 - val_accuracy: 0.9211\n",
      "Epoch 196/200\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.1606 - accuracy: 0.9140 - val_loss: 0.1446 - val_accuracy: 0.9211\n",
      "Epoch 197/200\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.1969 - accuracy: 0.9045 - val_loss: 0.1446 - val_accuracy: 0.9211\n",
      "Epoch 198/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1616 - accuracy: 0.9154 - val_loss: 0.1446 - val_accuracy: 0.9211\n",
      "Epoch 199/200\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.1999 - accuracy: 0.8967 - val_loss: 0.1446 - val_accuracy: 0.9211\n",
      "Epoch 200/200\n",
      "5/5 [==============================] - 0s 17ms/step - loss: 0.1806 - accuracy: 0.9036 - val_loss: 0.1446 - val_accuracy: 0.9211\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs = 200, shuffle = True, batch_size = 32,\n",
    "                    validation_data = (X_val, y_val), callbacks = [lrop, estop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Training Accuracy:  0.9205297827720642\n",
      "Final Validation Accuracy:  0.9210526347160339\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_accuracy = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "\n",
    "print('Final Training Accuracy: ', history.history['accuracy'][-1])\n",
    "print('Final Validation Accuracy: ', history.history['val_accuracy'][-1])\n",
    "\n",
    "plt.plot(training_accuracy, label='Training Accuracy')\n",
    "plt.plot(val_accuracy, label='Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 0.952\n"
     ]
    }
   ],
   "source": [
    "pred_labels = np.argmax(model.call(X_test.values).numpy(), axis=1)\n",
    "actual_labels = np.argmax(y_test.values, axis=1)\n",
    "\n",
    "print('Testing Accuracy:', accuracy_score(actual_labels, pred_labels).round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
