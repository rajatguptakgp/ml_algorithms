{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to /Users/r0g06z5/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/r0g06z5/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/r0g06z5/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import brown, stopwords\n",
    "import itertools\n",
    "from collections import Counter\n",
    "import json\n",
    "\n",
    "nltk.download('brown')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "stopwords = stopwords.words('english')\n",
    "\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Sense Disambiguation\n",
    "\n",
    "The problem of Word Sense Disambiguation (WSD) is identifying the correct sense of word being used in a sentence. In English Language, there can be multiple senses of the same word. \n",
    "\n",
    "For example - Apple in a sentence can be used as a fruit or as the name of company."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: ash\n",
      "Number of senses: 4\n",
      "\n",
      "Sense 1: the residue that remains when something is burned\n",
      "Sense 2: any of various deciduous pinnate-leaved ornamental or timber trees of the genus Fraxinus\n",
      "Sense 3: strong elastic wood of any of various ash trees; used for furniture and tool handles and sporting goods such as baseball bats\n",
      "Sense 4: convert into ashes\n"
     ]
    }
   ],
   "source": [
    "ambiguous_word = 'ash'\n",
    "word_senses = wn.synsets(ambiguous_word)\n",
    "print('Word:', ambiguous_word)\n",
    "print('Number of senses:', len(word_senses))\n",
    "print()\n",
    "for i, word_sense in enumerate(word_senses):\n",
    "    print(f'Sense {i+1}:', word_sense.definition())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Algorithm\n",
    "\n",
    "Given a sentence and an ambiguous word in it, we are interested in finding the sense of that word. So, we create **sense bags** which is collection of features (hyponyms/hypernyms/definitions or others) for each sense of ambiguous word and a **context bag** which is collection of features for all the words in sentence excluding ambiguous word.\n",
    "\n",
    "We calculate overlap between context bag and various sense bags (one for each sense). We consider that sense which has maximum overlap.\n",
    "\n",
    "1. Hyponyms are words of more specific meaning than given word. Example - Apple is hyponym of fruit.\n",
    "2. Hypernyms are words of broader meaning than given word. Example - Fruit is hypernym of Apple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sense_context_bag(sample_sentence, ambiguous_word, feature):\n",
    "    words = sample_sentence.split(' ')\n",
    "    words = [w.lower() for w in words]\n",
    "    words.remove(ambiguous_word)\n",
    "\n",
    "    sense_bag = []\n",
    "    context_bag = []\n",
    "    for word in words:\n",
    "        word_senses = wn.synsets(word)\n",
    "\n",
    "        if feature == 'hyponym':\n",
    "            word_hyponyms = list(itertools.chain(*map(lambda x: x.hyponyms(), word_senses)))\n",
    "            context_bag += word_hyponyms\n",
    "        if feature == 'hypernym':\n",
    "            word_hypernyms = list(itertools.chain(*map(lambda x: x.hypernyms(), word_senses)))\n",
    "            context_bag += word_hypernyms\n",
    "\n",
    "    ambiguous_word_senses = wn.synsets(ambiguous_word)\n",
    "    if feature=='hyponym':\n",
    "        sense_bag = list(map(lambda x: x.hyponyms(), ambiguous_word_senses))\n",
    "    if feature=='hypernym':\n",
    "        sense_bag = list(map(lambda x: x.hypernyms(), ambiguous_word_senses))\n",
    "    return sense_bag, set(context_bag)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sense(sample_sentence, ambiguous_word, feature):\n",
    "    sense_bag, context_bag = get_sense_context_bag(sample_sentence, ambiguous_word, feature)\n",
    "\n",
    "    # count overlap between context bag and various sense bags, one for each sense\n",
    "    count_overlap = list(map(lambda x: len(set(x) and context_bag), sense_bag))\n",
    "    sense_idx = count_overlap.index(max(count_overlap))\n",
    "    sense_dfn = wn.synsets(ambiguous_word)[sense_idx].definition()\n",
    "    return sense_dfn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ambiguous word: apple\n",
      "Definition: fruit with red or yellow or green skin and sweet to tart crisp whitish flesh\n"
     ]
    }
   ],
   "source": [
    "sample_sentence = 'I am eating apple'\n",
    "ambiguous_word = 'apple'\n",
    "feature = 'hyponym'\n",
    "sense_dfn = get_sense(sample_sentence, ambiguous_word, feature) \n",
    "print('Ambiguous word:', ambiguous_word)   \n",
    "print('Definition:', sense_dfn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(sense):\n",
    "    words = sense.definition().split()\n",
    "    words = [word.lower() for word in words if word.isalnum() and word not in stopwords]\n",
    "    return words\n",
    "\n",
    "def Lesk_algorithm(ambiguous_word, context):\n",
    "    sense_bag = list(map(lambda x: preprocess(x), wn.synsets(ambiguous_word)))\n",
    "\n",
    "    context_words = context.strip().split(' ')\n",
    "    context_bag = []\n",
    "    for context_word in context_words:\n",
    "        context_bag += list(itertools.chain(*map(lambda x: preprocess(x), wn.synsets(context_word))))\n",
    "    context_bag = set(context_bag)\n",
    "    \n",
    "    count_overlap = list(map(lambda x: len(set(x) and context_bag), sense_bag))\n",
    "    sense_idx = count_overlap.index(max(count_overlap))\n",
    "    sense_dfn = wn.synsets(ambiguous_word)[sense_idx].definition()\n",
    "    return sense_dfn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ambiguous word: ash\n",
      "Definition: the residue that remains when something is burned\n"
     ]
    }
   ],
   "source": [
    "ambiguous_word = 'ash'\n",
    "context = 'coal'\n",
    "sense_dfn = Lesk_algorithm(ambiguous_word, context)\n",
    "print('Ambiguous word:', ambiguous_word)   \n",
    "print('Definition:', sense_dfn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ambiguous word: burn\n",
      "Number of overlaps: [0, 0, 2, 0, 1, 2, 1, 3, 1, 2, 0, 0, 0, 0, 1, 0, 0, 1, 0, 2]\n",
      "Definition: undergo combustion\n"
     ]
    }
   ],
   "source": [
    "def get_thesaurus(sense):\n",
    "    return list(set(itertools.chain(*map(lambda x: x.lemma_names(), sense.hypernyms() + sense.hyponyms()))))\n",
    "\n",
    "def Walker_algorithm(ambiguous_word, context):\n",
    "    thesaurus_senses = list(map(lambda x: get_thesaurus(x), wn.synsets(ambiguous_word)))\n",
    "    assert len(thesaurus_senses) == len(wn.synsets(ambiguous_word))\n",
    "\n",
    "    context_words = context.strip().split(' ')\n",
    "    thesaurus_contexts = []\n",
    "    for context_word in context_words:\n",
    "        thesaurus_contexts += [list(set(itertools.chain(*map(lambda x: get_thesaurus(x), wn.synsets(context_word)))))]\n",
    "    assert len(thesaurus_contexts) == len(context_words)\n",
    "\n",
    "    count_overlaps = []\n",
    "    for thesaurus_sense in thesaurus_senses:\n",
    "        count_overlap = 0\n",
    "        for thesaurus_context in thesaurus_contexts:\n",
    "            if len(set(thesaurus_sense).intersection(set(thesaurus_context))) > 0:\n",
    "                count_overlap +=1\n",
    "        count_overlaps.append(count_overlap)\n",
    "        \n",
    "    print('Number of overlaps:', count_overlaps)\n",
    "    sense_idx = count_overlaps.index(max(count_overlaps))\n",
    "    sense_dfn = wn.synsets(ambiguous_word)[sense_idx].definition()\n",
    "    return sense_dfn\n",
    "\n",
    "ambiguous_word = 'burn'\n",
    "context = 'coal fire flame residue wood combust'\n",
    "\n",
    "print('Ambiguous word:', ambiguous_word)  \n",
    "sense_dfn = Walker_algorithm(ambiguous_word, context)\n",
    "print('Definition:', sense_dfn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "951daa5e1959839fcb325fff331f52e72634f7a1be998f6081ed7f433b63f1b3"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
