{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to /Users/r0g06z5/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/r0g06z5/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/r0g06z5/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import brown, stopwords\n",
    "import itertools\n",
    "from collections import Counter\n",
    "import json\n",
    "\n",
    "nltk.download('brown')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "stopwords = stopwords.words('english')\n",
    "\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of senses: 2\n"
     ]
    }
   ],
   "source": [
    "ambiguous_word = 'apple'\n",
    "word_senses = wn.synsets(ambiguous_word)\n",
    "print('Number of senses:', len(word_senses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sense(sample_sentence, ambiguous_word, feature):\n",
    "    words = sample_sentence.split(' ')\n",
    "    words = [w.lower() for w in words]\n",
    "    words.remove(ambiguous_word)\n",
    "\n",
    "    sense_bag = []\n",
    "    context_bag = []\n",
    "    for word in words:\n",
    "        word_senses = wn.synsets(word)\n",
    "\n",
    "        if feature == 'hyponym':\n",
    "            word_hyponyms = list(itertools.chain(*map(lambda x: x.hyponyms(), word_senses)))\n",
    "            context_bag += word_hyponyms\n",
    "        if feature == 'hypernym':\n",
    "            word_hypernyms = list(itertools.chain(*map(lambda x: x.hypernyms(), word_senses)))\n",
    "            context_bag += word_hypernyms\n",
    "\n",
    "    ambiguous_word_senses = wn.synsets(ambiguous_word)\n",
    "    if feature=='hyponym':\n",
    "        sense_bag = list(map(lambda x: x.hyponyms(), ambiguous_word_senses))\n",
    "    if feature=='hypernym':\n",
    "        sense_bag = list(map(lambda x: x.hypernyms(), ambiguous_word_senses))\n",
    "    return sense_bag, set(context_bag)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('edible_fruit.n.01'), Synset('pome.n.01')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_sentence = 'I am eating apple'\n",
    "ambiguous_word = 'apple'\n",
    "feature = 'hyponym'\n",
    "\n",
    "sense_bag, context_bag = get_sense(sample_sentence, ambiguous_word, feature)\n",
    "count_overlap = list(map(lambda x: len(set(x) and context_bag), sense_bag))\n",
    "sense_idx = count_overlap.index(max(count_overlap))\n",
    "wn.synsets(ambiguous_word)[sense_idx].hypernyms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(sense):\n",
    "    words = sense.definition().split()\n",
    "    words = [word.lower() for word in words if word.isalnum() and word not in stopwords]\n",
    "    return words\n",
    "\n",
    "context_bag = set(itertools.chain(*map(lambda x: preprocess(x), wn.synsets('coal'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sense_bag = list(map(lambda x: preprocess(x), wn.synsets('ash')))\n",
    "count_overlap = list(map(lambda x: len(set(x) and context_bag), sense_bag))\n",
    "sense_idx = count_overlap.index(max(count_overlap))\n",
    "sense_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "951daa5e1959839fcb325fff331f52e72634f7a1be998f6081ed7f433b63f1b3"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
