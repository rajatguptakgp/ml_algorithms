{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install onnx libraries\n",
    "\n",
    "# !pip install onnx\n",
    "# !pip install onnx_tf\n",
    "# !pip install onnx2keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and Loading PyTorch Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "\n",
    "# initializing a model with random weights\n",
    "model = models.resnet18()\n",
    "\n",
    "# initializing a model with pre-trained weights\n",
    "model = models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a PyTorch model file, complete model is stored while in a state file, only parameters are stored."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Saving state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# saving the model state\n",
    "# extension .pt/.pth\n",
    "torch.save(model.state_dict(), 'pytorch_weights.pth')\n",
    "\n",
    "# loading the model\n",
    "# initializing model with random weights\n",
    "model = models.resnet18()\n",
    "\n",
    "# loading the state dict\n",
    "model.load_state_dict(torch.load('pytorch_weights.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving model\n",
    "torch.save(model,'pytorch_model.pth')\n",
    "\n",
    "# loading model\n",
    "model = torch.load('pytorch_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and Loading Keras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "\n",
    "# instantiating a model\n",
    "model = ResNet50(weights='imagenet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. HDF5 format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# saving weights\n",
    "# serialize weights to HDF5\n",
    "model.save_weights('keras_weights.h5')\n",
    "\n",
    "# serialize model to JSON\n",
    "# json.loads takes string as input and returns dictionary as output\n",
    "model_json = json.loads(model.to_json())\n",
    "with open('keras_model.json', 'w') as f:\n",
    "    json.dump(model_json, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "\n",
    "# loading model\n",
    "# deserialize JSON to model\n",
    "with open('keras_model.json') as f:\n",
    "    model_json = json.load(f)\n",
    "\n",
    "# json.dumps takes dictionary as input and returns string as output \n",
    "model = model_from_json(json.dumps(model_json))\n",
    "\n",
    "# loading weights\n",
    "# deserialize HDF5 to model\n",
    "model.load_weights('keras_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Protobuf (.pb) format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: saved_model/assets\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# saving a model\n",
    "model.save('saved_model')\n",
    "\n",
    "# loading a model\n",
    "model = load_model('saved_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch to ONNX (Open Neural Network Exchange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "# loading pytorch model\n",
    "model = torch.load('pytorch_model.pth')\n",
    "dummy_input = torch.randn([10,3,244,244])\n",
    "\n",
    "# exporting model to ONNX format\n",
    "torch.onnx.export(model, dummy_input, 'resnet.onnx', verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ONNX to Tensorflow/Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unable to use `same` padding. Add ZeroPadding2D layer to fix shapes.\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "from onnx_tf.backend import prepare\n",
    "from onnx2keras import onnx_to_keras\n",
    "\n",
    "# onnx to tensorflow model\n",
    "model = onnx.load('resnet.onnx')\n",
    "tf_model = prepare(model)\n",
    "\n",
    "# onnx to keras model\n",
    "keras_model = onnx_to_keras(model, input_names = [node.name for node in model.graph.input], verbose=False)\n",
    "\n",
    "# save keras model\n",
    "# save weights\n",
    "keras_model.save_weights('onnx2keras_weights.h5')\n",
    "\n",
    "# serialize model to JSON\n",
    "model_json = json.loads(keras_model.to_json())\n",
    "with open('onnx2keras_model.json', 'w') as f:\n",
    "    json.dump(model_json, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f829e94",
   "metadata": {},
   "source": [
    "## Keras to TensorFlow Lite (TFLite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56bcd124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: /var/folders/88/brn_pbx106183309rb29k7lh0000gq/T/tmpxj0mt1ya/assets\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import tensorflow as tf\n",
    "from keras.models import model_from_json\n",
    "\n",
    "# loading keras model\n",
    "with open('keras_model.json') as f:\n",
    "    model_json = json.load(f)\n",
    "model = model_from_json(json.dumps(model_json))\n",
    "model.load_weights('keras_weights.h5')\n",
    "\n",
    "# tflite converter\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "\n",
    "# optimizations\n",
    "optimize_for_speed = False\n",
    "optimize_for_size = False\n",
    "\n",
    "if optimize_for_speed:\n",
    "    converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_LATENCY]\n",
    "elif optimize_for_size:\n",
    "    converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\n",
    "else:\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "# convert keras model to tflite\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# saving model\n",
    "with open('keras2tflite.tflite','wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d74d5979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT DETAILS\n",
      "{'name': 'input_1', 'index': 0, 'shape': array([  1, 224, 224,   3], dtype=int32), 'shape_signature': array([ -1, 224, 224,   3], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
      "\n",
      "OUTPUT DETAILS\n",
      "{'name': 'Identity', 'index': 186, 'shape': array([   1, 1000], dtype=int32), 'shape_signature': array([  -1, 1000], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n"
     ]
    }
   ],
   "source": [
    "# load model and allocate tensors\n",
    "tflite_model = tf.lite.Interpreter('keras2tflite.tflite')\n",
    "tensor_details = tflite_model.get_tensor_details()\n",
    "tflite_model.allocate_tensors()\n",
    "\n",
    "input_details = tflite_model.get_input_details()[0]\n",
    "output_details = tflite_model.get_output_details()[0]\n",
    "\n",
    "# input details\n",
    "print('INPUT DETAILS')\n",
    "print(input_details)\n",
    "\n",
    "# output details\n",
    "print('\\nOUTPUT DETAILS')\n",
    "print(output_details)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8560e56",
   "metadata": {},
   "source": [
    "### TFLite to Keras \n",
    "\n",
    "Since the model was optimized while converting Keras model to TFLite, and the weights were quantized potentially leading to loss of precision, converting TFLite model back to Keras might not lead to the same Keras model.\n",
    "\n",
    "The TFLite model contains information of weights which can be extracted. However, information of loss function and optimizer might not be available since it's not required during inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ccc47fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_dict = {}\n",
    "\n",
    "# extract weights from tflite model\n",
    "for tensor in tensor_details:\n",
    "    name = tensor['name']\n",
    "    weights = tflite_model.tensor(tensor['index'])()\n",
    "    weight_dict[name] = weights"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "951daa5e1959839fcb325fff331f52e72634f7a1be998f6081ed7f433b63f1b3"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
